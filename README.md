# Integração de LLM com API em Python e React  

Este projeto explora a integração de Large Language Models (LLMs) com uma API desenvolvida em Python e uma interface frontend construída em React. O objetivo foi criar uma aplicação prática que conectasse o poder dos modelos de linguagem a uma interface intuitiva, simulando uma interação fluida entre backend e frontend.  

<img src="https://github.com/user-attachments/assets/f7f16960-b2db-41b6-a60c-ed07a343c949" alt="Simulator Screenshot 1" width="200">

<img src="https://github.com/user-attachments/assets/b753af1a-6eca-45ff-8cd6-1c8872ca1907" alt="Simulator Screenshot 2" width="200">

<img src="https://github.com/user-attachments/assets/c1372b50-dab7-4d80-8b24-b80fad5b02e1" alt="Simulator Screenshot 3" width="200">

## Funcionalidades  
- **Interação com LLM:** O backend utiliza uma API para enviar prompts ao modelo de linguagem e retornar respostas.  
- **Frontend dinâmico:** Construído em React, o frontend apresenta uma interface responsiva para entrada e exibição das respostas.  
- **Fluxo otimizado:** Comunicação eficiente entre backend e frontend para garantir respostas rápidas e precisas.  

## Tecnologias Utilizadas  
- **Backend:** Python (FastAPI)  
- **Frontend:** React  
- **Comunicação:** REST API  
- **Styling:** CSS/Styled-components/Tailwind 

## Estrutura do Projeto  
- **backend/**: Contém a API Python responsável pela interação com o modelo de linguagem.  
- **frontend/**: Contém o código React para a interface do usuário.  
- **assets/**: Contém imagens e arquivos relacionados à aplicação.  

## Pré-requisitos  
- Python 3.8 ou superior  
- Node.js 14 ou superior  
- Gerenciador de pacotes (pip, npm ou yarn)  

## Como Executar  
1. Clone este repositório:  
   ```bash
   git clone https://github.com/seu-usuario/llm-integration.git  
   cd llm-integration
   ```
2. Inicie o backend
   ```bash
   cd backend
   pip install -r requirements.txt
   python app.py  
   ```
3. Inicie o frontend
   ```bash
  cd frontend  
  npm install  
  npm start  
  ```
4. Acesse o frontend ```bash http://localhost:3000``` e interaja com o LLM.

## Contribuição

Contribuições são bem-vindas! Sinta-se à vontade para abrir issues ou enviar pull requests.


