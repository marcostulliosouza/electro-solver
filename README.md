# Integração de LLM com API em Python e React  

Este projeto explora a integração de Large Language Models (LLMs) com uma API desenvolvida em Python e uma interface frontend construída em React. O objetivo foi criar uma aplicação prática que conectasse o poder dos modelos de linguagem a uma interface intuitiva, simulando uma interação fluida entre backend e frontend.  

<img src="https://github.com/user-attachments/assets/3cc29fc6-87fe-4f32-966a-1373798ddf86" alt="Simulator Screenshot 1" width="200">

<img src="https://github.com/user-attachments/assets/919852ca-f11e-47d6-98e0-9b62731e3264" alt="Simulator Screenshot 2" width="200">

<img src="https://github.com/user-attachments/assets/c4cef65d-b832-48b5-9222-861a1f873756" alt="Simulator Screenshot 3" width="200">


## Funcionalidades  
- **Interação com LLM:** O backend utiliza uma API para enviar prompts ao modelo de linguagem e retornar respostas.  
- **Frontend dinâmico:** Construído em React, o frontend apresenta uma interface responsiva para entrada e exibição das respostas.  
- **Fluxo otimizado:** Comunicação eficiente entre backend e frontend para garantir respostas rápidas e precisas.  

## Tecnologias Utilizadas  
- **Backend:** Python (FastAPI)  
- **Frontend:** React  
- **Comunicação:** REST API  
- **Styling:** CSS/Styled-components/Tailwind 

## Estrutura do Projeto  
- **backend/**: Contém a API Python responsável pela interação com o modelo de linguagem.  
- **frontend/**: Contém o código React para a interface do usuário.  
- **assets/**: Contém imagens e arquivos relacionados à aplicação.  

## Pré-requisitos  
- Python 3.8 ou superior  
- Node.js 14 ou superior  
- Gerenciador de pacotes (pip, npm ou yarn)  

## Como Executar  
1. Clone este repositório:  
   ```bash
   git clone https://github.com/seu-usuario/llm-integration.git  
   cd llm-integration
   ```
2. Inicie o backend
   ```bash
   cd backend
   pip install -r requirements.txt
   python app.py  
   ```
3. Inicie o frontend
   ```bash
  cd frontend  
  npm install  
  npm start  
  ```
4. Acesse o frontend ```bash http://localhost:3000``` e interaja com o LLM.

## Contribuição

Contribuições são bem-vindas! Sinta-se à vontade para abrir issues ou enviar pull requests.


